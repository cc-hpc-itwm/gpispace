Subject: RFC: Explicit memory management, iteration 0

- there is no alloc/free from within the workflow, this is a meta-issue and solved on the meta level. The virtual memory provides alloc/free that work with memory handles like now. A typical run would allocate memory, run the workflow with the handle (or mabye more than one) as additional parameter and later free the memory. Also we can re-use the same handle in different workflows or with the same workflow several times without freeing it in between.

- in the workflow a handle typically is split into memory locations of type

<struct name="memory_location">
  <field name="handle" type="memory_handle"/>
  <field name="offset" type="unsigned long"/>
  <field name="size" type="unsigned long"/>
</struct>

- the addition to the workflow language is a new tag <memory-transfer> that describes memory transfers in terms of locations. Via some in-port, the memory locations come into the module call. The values are copied at the momemt the transition is fired. That means that possible modifications are not influencing to locations that the data is copied to (although the modification of an output port would possible become visible in the workflow). Later the keyword "const" will forbid modifications.

<place name="data_location" type="memory_location"/>
<place name="available_location" type="memory_location"/>
<place name="randomized_data_location" type="memory_location"/>

<transition name="randomize">
  <defun>

    <in name="data_location" type="memory_location"/>
    <in name="available_location_in" type="memory_location"/>
    <out name="available_location_out" type="memory_location"/>
    <out name="randomized_data_location" type="memory_location"/>

    <memory-transfer name="data" from="data_location"/>
    <memory-transfer name="randomized_data" to="available_location_in"/>

    <module name="m"
            function="randomize ( data, data_location
                                , randomized_data, randomized_data_location
                                , available_location_in, available_location_out
                                )
                     "
    >
      <code><![CDATA[
      // prolog, generated
      // data = shmem_malloc (data_location.size);
      // randomized_data = shmem_malloc (available_location_in.size);
      // memcpy (data_location -> data)

      randomized_data_location = available_location_in;

      char* d (data);
      char* r (randomized_data);

      for (int i (0); i < data_location.size; ++i)
      {
        r[i] = d[i] ^ rand();
      }

      available_location_out = data_location;

      // epilog, generated
      // memcpy (randomized_data -> available_location_in)
      // shmem_free (randomized_data);
      // shmem_free (data);
      ]]></code>
    </module>
  </defun>
  <connect-in port="data_location" place="data_location"/>
  <connect-in port="available_location_in" place="available_location"/>
  <connect-out port="available_location_out" place="available_location"/>
  <connect-out port="randomized_data_location"
               place="randomized_data_location"/>
</transition>

- the memory transfer could also be connected to a port of type list<memory_location> to support striped data like in the frtm (see below), e.g.

  <in name="portion_of_velocity_cube" type="list of memory_location"/>
  <memory-transfer name="velocity" from="portion_of_velocity_cube"/>

- the generated code would

  unwrap_parameter_to_c
    get_memory into memory_locations, e.g.
      foreach (transfer t : transfers)
        foreach (location l : transfer)
          get (l)
    wait
  call function (parameter, memory_locations)
    put_memory from memory_locations
    wait
  wrap_parameter_to_workflow

  where get_memory and put_memory are new. Later (iteration optimize
fetch/get) we can make separate function in order to run get/put while
other function calls are in progress.

In iteration 0 we just use the existing shared memory to store the data,
throwing if there is not enough space.

- later (iteration optimize workflow memory_management) we can identify
and eliminate those puts that are followed by a get. This is especially
easy when the memory port is connected with an place directly but can be
done for expressions too.

- later (iteration make the scheduler locality aware) we can transport
the list of memory locations that is accessed by the module call to the
scheduler in order to run the task at the location where the copy costs
are low.

- the applications we know can work with it:

* smartb:
  - the subscriber will not fit with our model anyhow, so it should be a separate program that gets a handle and writes to it, independend of any workflow
  - the polling right now does polling and changes parts of the table, this is not possible in the new model, see link:smartb:polling, conceptual.jpg[] for a sketch on how to implement this within the new model: the poller reads the whole table and returns a list of flags that should be processed. That list is split into separate memory locations that are updated to be in progress and the processing of the message starts. once all elements of the list are updated, the poller can start again. after a certain message has been processed the location with the flag is updated to be free again. There are optimizations possible here (as there are now two more module calls per message), the point is that the model fits.

* frtm: does not use virtual memory right now, we could think of using it, e.g. to store the velocity cube. In this case we need to calculate the portion of the table that is accessed by a module call in before. This will be a geometric part of a cube, e.g. not a single memory location but a list of memory locations. The model must allow to connect a <memory-transfer> to a port of type list<memory_location> too. Note that this simplifies the polling in smartb too.
