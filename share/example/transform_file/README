:doctype: book
:toc:

= `share/examples/transform_file`: Transform an input file into an output file in parallel by applying a tranform operation

== Situation

The example demonstrates the modification of a given file in parallel using a Petri net workflow. +
This consists in applying a transformation operation to each item contained in the file.
The current example does the conversion of the alphabetic characters contained into a file to the upper-case.

Here the input file is split in blocks of equal sizes (excepting the last one) and these blocks (or chunks)
are then loaded in parallel into the virtual memory, parsed and tokenized. Afterwards, the found items 
are applied a transformation function, which is currently the conversion of an item to the upper case.
The transformed items are then stored into the write slots allocated into the virtual memory and written in
parallel into the output file. 

todo: implement a generic tranform operation, not only converting to upper case

== Compiling the example `transform_file`

The example is installed in share/example/transform_file

todo: specify the correct installation path here

todo: install the source files and the Makefile

In order to compile and run the example one should use the provided `link:Makefile[]`.

First step is to create a (temporary) folder where to build the example
and to keep the intermediary generated files.

Please note that for compiling and running the example, a valid installation of GPI-Space is required. 
In order to successfully compile and run the example, the user is required to supply the necessary input
parameters to the make command, which are:

* The name of input file that contains the items to transform. 
  This should be specified with an absolute path or with no path, in which case the file is considered to be into the current folder. 
* The name of the output file that contains the result of the application of the transform operation on the input file. 
  This should be specified with an absolute path or with no path, in which case the file is considered to be into the current folder. 
* The user may specify a value for the chunk size to use when reading the input file.
* The example also requires the specification of the number of read slots to be allocated into the virtual memory for loading the data.
* Also, the example requires the specification of the number of write slots to be allocated into the virtual memory.
* The user also is required to specify a build directory where to compile and store the intermediary files

The input file, the output file and the build directory are mandatory and should be specified initially by the user,
like in the following line:
  
  make INPUT_FILE="input_file.txt" OUTPUT_FILE="output_file.txt" BUILDDIR=/tmp/test
  
Omitting one of these parameters in the command line will result in an error, like below:

* Makefile:8: *** BUILDDIR not set, please specify the build directory.  Stop.
* Makefile:11: *** INPUT_FILE not set, please specify the name of the input file.  Stop.
* Makefile:15: *** OUTPUT_FILE not set, please specify the name of the output file.  Stop.

Please note that the build directory (here, /tmp/test) should already be created before invoking the command.

For the other parameters, optional values are proposed, like 1024 bytes for the chunk size, 10 read slots and 20 write slots.
The user can specify values in the command line for these, parameters, too, like in the line below:

  make INPUT_FILE="input_file.txt" OUTPUT_FILE="output_file.txt" CHUNK_SIZE=2048 READ_SLOTS=7 WRITE_SLOTS=15 BUILDDIR=/tmp/test
 
The result of the compilation are a bunch of files that are stored into the specified build directory. The user may find there 
the corresponding C++ generated code for the modules and the types specified into the .xpnet workflow description file, 
as well as the shared objects and libraries resulted from the automatic compilation of these. The corresponding shared libraries
are loaded by the workers at runtime during the execution of the workflow. 

== Running the example `transform_file`
For effectively running the example, the user should just execute the following command:

make run BUILDDIR=/tmp/test 

The user may completely skip the first step and this case the run command must contain at least the mandatory parameters
indicated above, like following:  

  make run INPUT_FILE="input_file.txt" OUTPUT_FILE="output_file.txt" BUILDDIR=/tmp/test
 
In this case the default values will be used for the optional parameters but the user has the freedom 
to chose a value for them, as well, as in the following command:

  make run INPUT_FILE="input_file.txt" OUTPUT_FILE="output_file.txt" CHUNK_SIZE=2048 READ_SLOTS=7 WRITE_SLOTS=15 BUILDDIR=/tmp/test

to do: give example of a simple input file and explain how the user can easily generate one
(e.g. use ```echo "Some text that contains lower and upper case letters" > input_file.txt```)

to do: for the chose input file explain what the expected output should be  

During the execution, the example will print on the screen useful logging information related 
to the execution of the modules, like below:

....
[1397139683.870830] I: we-exec we-exec.cpp:161 - SDPA layer worker-1 started
[1397139683.870831] I: we-exec we-exec.cpp:161 - SDPA layer worker-0 started
[1397139683.884800] I: create_config create_config.cpp:34 - The number of read slots to be used is 7
[1397139683.884838] I: create_config create_config.cpp:35 - The number of write slots to be used is 15
[1397139683.917863] I: create_config create_config.cpp:72 - The file should be splitted into 7 chunks, where chunk_size =1024!
[1397139683.917920] I: create_config create_config.cpp:75 - The number of nodes used by GPI: 1
[1397139683.917982] I: create_config create_config.cpp:82 - Size of the read area to be allocated: 7168
[1397139683.918038] I: create_config create_config.cpp:83 - Size of the write area to be allocated: 15360
[1397139683.936743] I: default read_and_load_chunk.cpp:65 - The chunk 0 was successfully into the virtual memory
[1397139683.945669] I: default read_and_load_chunk.cpp:65 - The chunk 1 was successfully into the virtual memory
[1397139683.955291] I: default read_and_load_chunk.cpp:65 - The chunk 2 was successfully into the virtual memory
[1397139683.964533] I: default transform_words.cpp:24 - Transform the chunk 0 now...
[1397139683.973296] I: default transform_words.cpp:24 - Transform the chunk 1 now...
[1397139683.982790] I: write_chunk write_chunk.cpp:34 - write the chunk 0 now ...
[1397139683.991422] I: default transform_words.cpp:24 - Transform the chunk 2 now...
[1397139684.000296] I: write_chunk write_chunk.cpp:34 - write the chunk 1 now ...
[1397139684.012194] I: write_chunk write_chunk.cpp:34 - write the chunk 2 now ...
[1397139684.024866] I: default read_and_load_chunk.cpp:65 - The chunk 3 was successfully into the virtual memory
[1397139684.034028] I: default transform_words.cpp:24 - Transform the chunk 3 now...
[1397139684.043843] I: write_chunk write_chunk.cpp:34 - write the chunk 3 now ...
[1397139684.053672] I: default read_and_load_chunk.cpp:65 - The chunk 4 was successfully into the virtual memory
[1397139684.062828] I: default transform_words.cpp:24 - Transform the chunk 4 now...
[1397139684.072814] I: write_chunk write_chunk.cpp:34 - write the chunk 4 now ...
[1397139684.083281] I: default read_and_load_chunk.cpp:65 - The chunk 5 was successfully into the virtual memory
[1397139684.093406] I: default read_and_load_chunk.cpp:65 - The chunk 6 was successfully into the virtual memory
[1397139684.102086] I: default transform_words.cpp:24 - Transform the chunk 5 now...
[1397139684.111412] I: default transform_words.cpp:24 - Transform the chunk 6 now...
[1397139684.121021] I: write_chunk write_chunk.cpp:34 - write the chunk 5 now ...
[1397139684.129797] I: write_chunk write_chunk.cpp:34 - write the chunk 6 now ...
finished [1]
done => []
....

Analyzing the Petri net workflow that is stored into the transform_file.xpnet file, the user can see that this
contains several place and transition definitions. Some transitions contain module calls, which are automatically scheduled 
to the available workers existing in the system and executed. In this workflow there are four modules defined:

* create_config: this module is called only once, in the beginning and is responsible with allocating memory into the virtual address space 
                and prepare necessary configuration data that is to be passed to other modules afterwards.
* read_and_load_chunk: this module reads a chunk with a specified id from the input files and stores into the virtual memory at a specified location (into a given read slot)
* transform_words: this module reads from the virtual memory the data stored into a given read slot, applies the transformation operation to the found items and afterwards 
                   store the result into a specified location in the virtual memory (into a write slot) 
* write_chunk: writes the data stored into a write slot in the virtual memory at a specified position of the output file corresponding to the original chunk id. 

== Cleaning the generated files 
Erasing all the files and data generated during the compilation can be done by invoking the command:

make clean BUILDDIR=/tmp/test 

The user is additionally responsible with deleting the output file resulted from the transformation of the specified input file.
